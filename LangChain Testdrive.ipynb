{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Testdrive\n",
    "\n",
    "This notebooks are a series of testdrives with the [langchain](https://python.langchain.com/) Framework. I start off with the ones from the [Quickstart](https://python.langchain.com/docs/get_started/quickstart.html) section and build up from there to something interesting - wherever my head takes me."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing LangChain and OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install langchain with a simple `pip install`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain needs access to LLM Provider. I am using OpenAI here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing OpenAI requires an API key. I have created an account there first. On the [API keys](https://platform.openai.com/account/api-keys) page on OpenAI, you can create an API key. Set the API Key as an environment variable `OPENAI_API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the API key from the user directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "OPENAI_API_KEY = getpass('OpenAI API Key')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from OpenAI with LangChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's basic building block is the LLM. Here we use OpenAI to provide some texts on a given Prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we setup the llm to be OpenAI and we set the temperature to a high value, so that the responses are more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9, \n",
    "             openai_api_key=OPENAI_API_KEY) #You can set the API key here as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nFrankfurter.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What would be a good name for a dog coming from Frankfurt?\"\n",
    "llm.predict(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Name-A-Pet GPT - Prompt Templates and Chains\n",
    "\n",
    "Now we have the building blocks for building a service, where a user could get good suggestions for a pet name. However we direct the user and let him not bother him on getting the right prompt for the LLM. This is where we use `PromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What would be a good name for a cat coming from Darmstadt?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What would be a good name for a {pet} coming from {location}?\")\n",
    "prompt.format(pet=\"cat\", location=\"Darmstadt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the LLM and the prompt template. To combine the two to get a prediction, we chain the two building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nDarmy the Cat.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(pet=\"cat\", location=\"Darmstadt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now wrap this in an API and build a WebApp in front of it and voil√° you have a web service for generating pet names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Stock Idea Generator\n",
    "\n",
    "***This is just a fun project. Please do your own research when it comes to investing or consult a registered financial advisor. Whatever the code is generating below, is not an investment advise***\n",
    "\n",
    "I like investing in Stocks and coming up for new ideas for investing could be a very interesting use case.\n",
    "\n",
    "For this we want to create a more complex chain with LangChain. The idea is to use the `Agent` to create a conversational ChatBot. The agent will use Google Search to get more context on the prompts provided and use them in the LLM to provide up to date and hopefully very interesting results!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "First step is to install some more libraries. Here we get the `google-search-results` python package. It uses the [SerpApi](serpapi.com). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the App"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get yourself registered on [SerpApi](serpapi.com). There is a free subscription available that allows a few requests on their service per month. On [SerpApi's API Key page](https://serpapi.com/manage-api-key) you will get the `SERP_API_KEY`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERP_API_KEY = getpass('Serp API Key')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are integrations to other services in the LangChain that provide the LLM with more context. Here we are using Google search results. When defining a tool, a `description` is important. The LLM model in LangChain decides according to this description, whether the tool will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=SERP_API_KEY)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Current Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world or latest information on companies and stocks\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the context within the conversation, the `ConversaionBufferMemory` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just initialize the LLM, the tools and memory and the agent is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "agent_chain = initialize_agent(tools=tools, \n",
    "                               llm=llm, \n",
    "                               agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                               verbose=True, \n",
    "                               memory=memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the Prompts from the user and get the conversation going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Current Search\n",
      "Action Input: 10 stocks with growth potential in EMEA with best-in-class sustainability\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m10 Best Stocks for Environmental, Social, and Governance (ESG) Investing ¬∑ 10 best ESG stocks right now ¬∑ 1. Nvidia ¬∑ 2. Microsoft ¬∑ 3. Best Buy ¬∑ 4. Adobe ¬∑ 5. Pool.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Here are the 10 stocks with growth potential in EMEA that have best-in-class sustainability: Nvidia, Microsoft, Best Buy, Adobe, Pool, Apple, Amazon, Alphabet, Johnson & Johnson, and Unilever. I hope this helps you make an informed decision.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are the 10 stocks with growth potential in EMEA that have best-in-class sustainability: Nvidia, Microsoft, Best Buy, Adobe, Pool, Apple, Amazon, Alphabet, Johnson & Johnson, and Unilever. I hope this helps you make an informed decision.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\n",
    "                \"\"\"I am a risk-averse investor and I am interested in stocks in EMEA. \n",
    "                Can you list me 10 stocks with growth potential? \n",
    "                Please ensure that the companies listed are the best-in-class in sustainability.\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Current Search\n",
      "Action Input: List 3 stocks from EMEA with growth potential and best-in-class sustainability\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPut a little green in your wallet by investing in these growing areas. ... Eco-friendly investments can provide profits as well as environmental benefits.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: The three stocks from EMEA with growth potential and best-in-class sustainability are Nvidia, Microsoft, and Unilever. Investing in these stocks can provide both financial and environmental benefits.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The three stocks from EMEA with growth potential and best-in-class sustainability are Nvidia, Microsoft, and Unilever. Investing in these stocks can provide both financial and environmental benefits.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\n",
    "                \"\"\"Limit the list to 3 stocks that are from EMEA.\n",
    "                \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, Nvidia, Microsoft are US based companies. But as we see, how easy it is to build specialized AI solutions with LLMs and then LangChain framework, there is no wonder that Nvidia and Microsoft are rated to highly by this tool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
